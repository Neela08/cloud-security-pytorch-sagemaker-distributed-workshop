{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PyTorch Native Distributed Training with Amazon SageMaker***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker --upgrade -q\n",
    "# !pip install ipywidgets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import essentials packages, start a sagemaker session and specify the bucket name you created in the pre-requsites section of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_name    = sagemaker_session.default_bucket()\n",
    "jobs_folder    = 'jobs'\n",
    "dataset_folder = 'datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1000/0*GRfvsrvtfpRm400-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the training data\n",
    "The CIFAR-10 dataset is a subset of the 80 million tiny images dataset. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10('cifar10-dataset', \n",
    "                                     train=True, \n",
    "                                     download=True)\n",
    "\n",
    "datasets = sagemaker_session.upload_data(path='cifar10-dataset', \n",
    "                                         key_prefix=f'{dataset_folder}/cifar10-dataset')\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Specify hyperparameters, instance type and number of instances to distribute training to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name   = f'pytorch-native-dist-{time.strftime(\"%Y-%m-%d-%H-%M-%S-%j\", time.gmtime())}'\n",
    "output_path = f's3://{bucket_name}/{jobs_folder}'\n",
    "\n",
    "hyperparameters = {'epochs'       : 20, \n",
    "                   'lr'           : 0.01,\n",
    "                   'momentum'     : 0.9,\n",
    "                   'batch-size'   : 64,\n",
    "                   'model-type'   : 'custom',\n",
    "                   'backend'      : 'gloo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "estimator = PyTorch(entry_point         = 'cifar10-distributed-native-cpu.py', \n",
    "                           source_dir           = 'code',\n",
    "                           output_path          = output_path + '/',\n",
    "                           code_location        = output_path,\n",
    "                           role                 = role,\n",
    "                           instance_count       = 2,\n",
    "                           instance_type        = 'ml.c5.2xlarge',\n",
    "                           framework_version    = '1.8.0', \n",
    "                           py_version           = 'py3',\n",
    "                           hyperparameters      = hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Specify dataset locations in Amazon S3 and then call the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.fit({'train': datasets}, \n",
    "              job_name=job_name, \n",
    "              wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "def test_data_loader():\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    testset = torchvision.datasets.CIFAR10(root=\"cifar10-dataset\", \n",
    "                                           train=False, \n",
    "                                           download=False, \n",
    "                                           transform=transform)                                            \n",
    "    return torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "def show_img(img):\n",
    "    \"\"\"displays an image\"\"\"\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some test images\n",
    "dataiter = iter(test_data_loader())\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images, labels, and predictions\n",
    "show_img(torchvision.utils.make_grid(images))\n",
    "print(\"GroundTruth: \", \" \".join(\"%4s\" % classes[labels[j]] for j in range(4)))\n",
    "outputs = predictor.predict(images)\n",
    "_, predicted = torch.max(torch.from_numpy(np.array(outputs)), 1)\n",
    "\n",
    "print(\"Predicted:   \", \" \".join(\"%4s\" % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
