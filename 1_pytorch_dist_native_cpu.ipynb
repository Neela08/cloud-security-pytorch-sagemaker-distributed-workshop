{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PyTorch Native Distributed Training with Amazon SageMaker***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sagemaker --upgrade -q\n",
    "# !pip install ipywidgets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:** Import essentials packages, start a sagemaker session and specify the bucket name you created in the pre-requsites section of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import time\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_name    = sagemaker_session.default_bucket()\n",
    "jobs_folder    = 'jobs'\n",
    "dataset_folder = 'datasets'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1000/0*GRfvsrvtfpRm400-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the training data\n",
    "The CIFAR-10 dataset is a subset of the 80 million tiny images dataset. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-453691756499/datasets/cifar10-dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "cifar10_dataset = torchvision.datasets.CIFAR10('cifar10-dataset', \n",
    "                                     train=True, \n",
    "                                     download=True)\n",
    "\n",
    "datasets = sagemaker_session.upload_data(path='cifar10-dataset', \n",
    "                                         key_prefix=f'{dataset_folder}/cifar10-dataset')\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** Specify hyperparameters, instance type and number of instances to distribute training to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name   = f'pytorch-native-dist-{time.strftime(\"%Y-%m-%d-%H-%M-%S-%j\", time.gmtime())}'\n",
    "output_path = f's3://{bucket_name}/{jobs_folder}'\n",
    "\n",
    "hyperparameters = {'epochs'       : 20, \n",
    "                   'lr'           : 0.01,\n",
    "                   'momentum'     : 0.9,\n",
    "                   'batch-size'   : 64,\n",
    "                   'model-type'   : 'custom',\n",
    "                   'backend'      : 'gloo'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "estimator = PyTorch(entry_point         = 'cifar10-distributed-native-cpu.py', \n",
    "                           source_dir           = 'code',\n",
    "                           output_path          = output_path + '/',\n",
    "                           code_location        = output_path,\n",
    "                           role                 = role,\n",
    "                           instance_count       = 2,\n",
    "                           instance_type        = 'ml.c5.2xlarge',\n",
    "                           framework_version    = '1.8.0', \n",
    "                           py_version           = 'py3',\n",
    "                           hyperparameters      = hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Specify dataset locations in Amazon S3 and then call the fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-21 09:45:10 Starting - Starting the training job...\n",
      "2022-06-21 09:45:33 Starting - Preparing the instances for trainingProfilerReport-1655804710: InProgress\n",
      "......\n",
      "2022-06-21 09:46:34 Downloading - Downloading input data...\n",
      "2022-06-21 09:46:58 Training - Downloading the training image...\n",
      "2022-06-21 09:47:34 Training - Training image download completed. Training in progress.\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,631 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,633 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,646 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,652 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,938 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,949 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,959 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2022-06-21 09:47:25,968 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 20,\n",
      "        \"lr\": 0.01,\n",
      "        \"model-type\": \"custom\",\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-native-dist-2022-06-21-09-45-09-172\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-453691756499/jobs/pytorch-native-dist-2022-06-21-09-45-09-172/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10-distributed-native-cpu\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10-distributed-native-cpu.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"backend\":\"gloo\",\"batch-size\":64,\"epochs\":20,\"lr\":0.01,\"model-type\":\"custom\",\"momentum\":0.9}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=cifar10-distributed-native-cpu.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=cifar10-distributed-native-cpu\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-us-west-2-453691756499/jobs/pytorch-native-dist-2022-06-21-09-45-09-172/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"batch-size\":64,\"epochs\":20,\"lr\":0.01,\"model-type\":\"custom\",\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-native-dist-2022-06-21-09-45-09-172\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-453691756499/jobs/pytorch-native-dist-2022-06-21-09-45-09-172/source/sourcedir.tar.gz\",\"module_name\":\"cifar10-distributed-native-cpu\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10-distributed-native-cpu.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--batch-size\",\"64\",\"--epochs\",\"20\",\"--lr\",\"0.01\",\"--model-type\",\"custom\",\"--momentum\",\"0.9\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[35mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[35mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[35mSM_HP_MODEL-TYPE=custom\u001b[0m\n",
      "\u001b[35mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.6 cifar10-distributed-native-cpu.py --backend gloo --batch-size 64 --epochs 20 --lr 0.01 --model-type custom --momentum 0.9\u001b[0m\n",
      "\u001b[35mDistributed training - True\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:25,659 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:25,661 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:25,671 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:25,677 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:26,010 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:26,022 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:26,033 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-06-21 09:47:26,042 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"backend\": \"gloo\",\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 20,\n",
      "        \"lr\": 0.01,\n",
      "        \"model-type\": \"custom\",\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-native-dist-2022-06-21-09-45-09-172\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-453691756499/jobs/pytorch-native-dist-2022-06-21-09-45-09-172/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"cifar10-distributed-native-cpu\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"cifar10-distributed-native-cpu.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"backend\":\"gloo\",\"batch-size\":64,\"epochs\":20,\"lr\":0.01,\"model-type\":\"custom\",\"momentum\":0.9}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=cifar10-distributed-native-cpu.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=cifar10-distributed-native-cpu\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-453691756499/jobs/pytorch-native-dist-2022-06-21-09-45-09-172/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"backend\":\"gloo\",\"batch-size\":64,\"epochs\":20,\"lr\":0.01,\"model-type\":\"custom\",\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-native-dist-2022-06-21-09-45-09-172\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-453691756499/jobs/pytorch-native-dist-2022-06-21-09-45-09-172/source/sourcedir.tar.gz\",\"module_name\":\"cifar10-distributed-native-cpu\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.2xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"cifar10-distributed-native-cpu.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--backend\",\"gloo\",\"--batch-size\",\"64\",\"--epochs\",\"20\",\"--lr\",\"0.01\",\"--model-type\",\"custom\",\"--momentum\",\"0.9\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BACKEND=gloo\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL-TYPE=custom\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 cifar10-distributed-native-cpu.py --backend gloo --batch-size 64 --epochs 20 --lr 0.01 --model-type custom --momentum 0.9\u001b[0m\n",
      "\u001b[34mDistributed training - True\u001b[0m\n",
      "\u001b[35mInitialized the distributed environment: 'gloo' backend on 2 nodes. \u001b[0m\n",
      "\u001b[35mGet train data loader\u001b[0m\n",
      "\u001b[34mInitialized the distributed environment: 'gloo' backend on 2 nodes. \u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[35mGet test data loader\u001b[0m\n",
      "\u001b[35mProcesses 25000/50000 (50%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.346 algo-2:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.624 algo-2:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.624 algo-2:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.625 algo-2:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.625 algo-2:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.625 algo-2:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.654 algo-2:26 INFO hook.py:584] name:module.conv1.weight count_params:450\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.654 algo-2:26 INFO hook.py:584] name:module.conv1.bias count_params:6\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.conv2.weight count_params:2400\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.conv2.bias count_params:16\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.fc1.weight count_params:48000\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.fc1.bias count_params:120\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.fc2.weight count_params:10080\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.fc2.bias count_params:84\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.fc3.weight count_params:840\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:584] name:module.fc3.bias count_params:10\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:586] Total Trainable Params: 62006\u001b[0m\n",
      "\u001b[35m[2022-06-21 09:47:29.655 algo-2:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34mProcesses 25000/50000 (50%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 10000/10000 (100%) of test data\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.353 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.680 algo-1:26 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.680 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.680 algo-1:26 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.681 algo-1:26 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.681 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.723 algo-1:26 INFO hook.py:584] name:module.conv1.weight count_params:450\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.conv1.bias count_params:6\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.conv2.weight count_params:2400\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.conv2.bias count_params:16\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.fc1.weight count_params:48000\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.fc1.bias count_params:120\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.fc2.weight count_params:10080\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.fc2.bias count_params:84\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.fc3.weight count_params:840\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:584] name:module.fc3.bias count_params:10\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:586] Total Trainable Params: 62006\u001b[0m\n",
      "\u001b[34m[2022-06-21 09:47:29.724 algo-1:26 INFO hook.py:413] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [6400/25000 (26%)] Loss: 2.078174\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [6400/25000 (26%)] Loss: 2.117595\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [12800/25000 (51%)] Loss: 2.035070\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [12800/25000 (51%)] Loss: 1.822954\u001b[0m\n",
      "\u001b[34mTrain Epoch: 1 [19200/25000 (77%)] Loss: 1.777211\u001b[0m\n",
      "\u001b[35mTrain Epoch: 1 [19200/25000 (77%)] Loss: 1.874125\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -1.2011, Accuracy: 0.39\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -1.2011, Accuracy: 0.39\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [6400/25000 (26%)] Loss: 1.449694\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [6400/25000 (26%)] Loss: 1.388150\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [12800/25000 (51%)] Loss: 1.391975\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [12800/25000 (51%)] Loss: 1.626726\u001b[0m\n",
      "\u001b[35mTrain Epoch: 2 [19200/25000 (77%)] Loss: 1.564608\u001b[0m\n",
      "\u001b[34mTrain Epoch: 2 [19200/25000 (77%)] Loss: 1.725243\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -1.5805, Accuracy: 0.47\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -1.5805, Accuracy: 0.47\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [6400/25000 (26%)] Loss: 1.339296\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [6400/25000 (26%)] Loss: 1.152442\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [12800/25000 (51%)] Loss: 1.269444\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [12800/25000 (51%)] Loss: 1.511233\u001b[0m\n",
      "\u001b[35mTrain Epoch: 3 [19200/25000 (77%)] Loss: 1.328532\u001b[0m\n",
      "\u001b[34mTrain Epoch: 3 [19200/25000 (77%)] Loss: 1.438142\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -1.9070, Accuracy: 0.49\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -1.9070, Accuracy: 0.49\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [6400/25000 (26%)] Loss: 1.357175\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [6400/25000 (26%)] Loss: 1.152379\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [12800/25000 (51%)] Loss: 1.192525\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [12800/25000 (51%)] Loss: 1.386630\u001b[0m\n",
      "\u001b[35mTrain Epoch: 4 [19200/25000 (77%)] Loss: 1.305134\u001b[0m\n",
      "\u001b[34mTrain Epoch: 4 [19200/25000 (77%)] Loss: 1.400580\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.1873, Accuracy: 0.52\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.1873, Accuracy: 0.52\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [6400/25000 (26%)] Loss: 1.143814\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [6400/25000 (26%)] Loss: 1.194647\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [12800/25000 (51%)] Loss: 1.389444\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [12800/25000 (51%)] Loss: 1.081273\u001b[0m\n",
      "\u001b[34mTrain Epoch: 5 [19200/25000 (77%)] Loss: 1.461507\u001b[0m\n",
      "\u001b[35mTrain Epoch: 5 [19200/25000 (77%)] Loss: 1.316719\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.1977, Accuracy: 0.53\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.1977, Accuracy: 0.53\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [6400/25000 (26%)] Loss: 1.035303\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [6400/25000 (26%)] Loss: 0.960706\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [12800/25000 (51%)] Loss: 0.961902\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [12800/25000 (51%)] Loss: 1.334687\u001b[0m\n",
      "\u001b[35mTrain Epoch: 6 [19200/25000 (77%)] Loss: 1.133401\u001b[0m\n",
      "\u001b[34mTrain Epoch: 6 [19200/25000 (77%)] Loss: 1.346866\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.4631, Accuracy: 0.55\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.4631, Accuracy: 0.55\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [6400/25000 (26%)] Loss: 1.140041\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [6400/25000 (26%)] Loss: 0.800374\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [12800/25000 (51%)] Loss: 1.063636\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [12800/25000 (51%)] Loss: 1.352433\u001b[0m\n",
      "\u001b[35mTrain Epoch: 7 [19200/25000 (77%)] Loss: 1.022027\u001b[0m\n",
      "\u001b[34mTrain Epoch: 7 [19200/25000 (77%)] Loss: 1.210925\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.5515, Accuracy: 0.55\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.5515, Accuracy: 0.55\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [6400/25000 (26%)] Loss: 0.976059\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [6400/25000 (26%)] Loss: 1.137774\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [12800/25000 (51%)] Loss: 1.220563\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [12800/25000 (51%)] Loss: 0.955464\u001b[0m\n",
      "\u001b[34mTrain Epoch: 8 [19200/25000 (77%)] Loss: 1.292230\u001b[0m\n",
      "\u001b[35mTrain Epoch: 8 [19200/25000 (77%)] Loss: 1.151829\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.6649, Accuracy: 0.57\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.6649, Accuracy: 0.57\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [6400/25000 (26%)] Loss: 0.870762\u001b[0m\n",
      "\u001b[35mTrain Epoch: 9 [6400/25000 (26%)] Loss: 1.034831\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [12800/25000 (51%)] Loss: 1.163163\u001b[0m\n",
      "\u001b[35mTrain Epoch: 9 [12800/25000 (51%)] Loss: 1.043386\u001b[0m\n",
      "\u001b[34mTrain Epoch: 9 [19200/25000 (77%)] Loss: 1.224927\u001b[0m\n",
      "\u001b[35mTrain Epoch: 9 [19200/25000 (77%)] Loss: 0.957771\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.8878, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.8878, Accuracy: 0.58\u001b[0m\n",
      "\u001b[35mTrain Epoch: 10 [6400/25000 (26%)] Loss: 0.942893\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [6400/25000 (26%)] Loss: 0.781547\u001b[0m\n",
      "\u001b[35mTrain Epoch: 10 [12800/25000 (51%)] Loss: 0.998517\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [12800/25000 (51%)] Loss: 1.170910\u001b[0m\n",
      "\u001b[35mTrain Epoch: 10 [19200/25000 (77%)] Loss: 1.068445\u001b[0m\n",
      "\u001b[34mTrain Epoch: 10 [19200/25000 (77%)] Loss: 1.299746\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.9525, Accuracy: 0.57\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.9525, Accuracy: 0.57\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [6400/25000 (26%)] Loss: 0.804938\u001b[0m\n",
      "\u001b[35mTrain Epoch: 11 [6400/25000 (26%)] Loss: 0.958561\u001b[0m\n",
      "\u001b[35mTrain Epoch: 11 [12800/25000 (51%)] Loss: 1.011809\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [12800/25000 (51%)] Loss: 1.059916\u001b[0m\n",
      "\u001b[35mTrain Epoch: 11 [19200/25000 (77%)] Loss: 0.958926\u001b[0m\n",
      "\u001b[34mTrain Epoch: 11 [19200/25000 (77%)] Loss: 1.137194\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.8908, Accuracy: 0.58\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.8908, Accuracy: 0.58\u001b[0m\n",
      "\u001b[35mTrain Epoch: 12 [6400/25000 (26%)] Loss: 1.116268\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [6400/25000 (26%)] Loss: 0.909705\u001b[0m\n",
      "\u001b[35mTrain Epoch: 12 [12800/25000 (51%)] Loss: 0.923749\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [12800/25000 (51%)] Loss: 1.030755\u001b[0m\n",
      "\u001b[35mTrain Epoch: 12 [19200/25000 (77%)] Loss: 1.007082\u001b[0m\n",
      "\u001b[34mTrain Epoch: 12 [19200/25000 (77%)] Loss: 1.124818\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -2.9891, Accuracy: 0.59\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -2.9891, Accuracy: 0.59\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [6400/25000 (26%)] Loss: 0.697019\u001b[0m\n",
      "\u001b[35mTrain Epoch: 13 [6400/25000 (26%)] Loss: 1.090556\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [12800/25000 (51%)] Loss: 1.236995\u001b[0m\n",
      "\u001b[34mTrain Epoch: 13 [19200/25000 (77%)] Loss: 1.044946\u001b[0m\n",
      "\u001b[35mTrain Epoch: 13 [12800/25000 (51%)] Loss: 0.780276\u001b[0m\n",
      "\u001b[35mTrain Epoch: 13 [19200/25000 (77%)] Loss: 0.997349\u001b[0m\n",
      "\u001b[35mTest set: Average loss: -3.0983, Accuracy: 0.60\u001b[0m\n",
      "\u001b[34mTest set: Average loss: -3.0983, Accuracy: 0.60\u001b[0m\n",
      "\u001b[35mTrain Epoch: 14 [6400/25000 (26%)] Loss: 0.892466\u001b[0m\n",
      "\u001b[34mTrain Epoch: 14 [6400/25000 (26%)] Loss: 0.818928\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': datasets}, \n",
    "              job_name=job_name, \n",
    "              wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    model_data=estimator.model_data,\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    ")\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "classes = (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "def test_data_loader():\n",
    "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), \n",
    "                                                torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "    testset = torchvision.datasets.CIFAR10(root=\"cifar10-dataset\", \n",
    "                                           train=False, \n",
    "                                           download=False, \n",
    "                                           transform=transform)                                            \n",
    "    return torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "def show_img(img):\n",
    "    \"\"\"displays an image\"\"\"\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some test images\n",
    "dataiter = iter(test_data_loader())\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images, labels, and predictions\n",
    "show_img(torchvision.utils.make_grid(images))\n",
    "print(\"GroundTruth: \", \" \".join(\"%4s\" % classes[labels[j]] for j in range(4)))\n",
    "outputs = predictor.predict(images)\n",
    "_, predicted = torch.max(torch.from_numpy(np.array(outputs)), 1)\n",
    "\n",
    "print(\"Predicted:   \", \" \".join(\"%4s\" % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
